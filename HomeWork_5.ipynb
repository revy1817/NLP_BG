{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HomeWork.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CtSF-3Tks4ul"
      ],
      "mount_file_id": "1YfQ6Ew4uzcerC3k4AkHOyowCPBUEbw7P",
      "authorship_tag": "ABX9TyNH/BV/S1dBiX15V5SSU8qs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/revy1817/NLP_BG/blob/less_1_hw/HomeWork_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyconll sklearn_crfsuite corus razdel  spacy pyconll tensorflow"
      ],
      "metadata": {
        "id": "R2Za3ZOu2z38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df42f59-8214-4d5c-c23c-75a7568c19d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyconll\n",
            "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Collecting corus\n",
            "  Downloading corus-0.9.0-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.64.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.10)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.7.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, razdel, pyconll, corus\n",
            "Successfully installed corus-0.9.0 pyconll-3.1.0 python-crfsuite-0.9.8 razdel-0.5.0 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m venv env \n",
        "# .\\env\\Scripts\\activate.bat\n",
        "!pip install deeppavlov\n",
        "!python -m deeppavlov install squad_bert\n",
        "\n",
        "!python -m deeppavlov install ner_ontonotes"
      ],
      "metadata": {
        "id": "bG4HOezDlNux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyconll\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.random import seed\n",
        "\n",
        "from corus import load_ne5\n",
        "from razdel import tokenize\n",
        "import spacy\n",
        "# import deeppavlov\n",
        "# from deeppavlov import configs, build_model\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras import Sequential, Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "\n",
        "import nltk\n",
        "from nltk.tag import DefaultTagger, BigramTagger, TrigramTagger, UnigramTagger\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics"
      ],
      "metadata": {
        "id": "jyKjLnuc2tn-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dXU8QYQ3Zup",
        "outputId": "576b46b5-2af4-4e6b-8d34-86922d2415f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание №1:** Написать теггер на данных с русским языком"
      ],
      "metadata": {
        "id": "CtSF-3Tks4ul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJJ2seHKsOb8"
      },
      "outputs": [],
      "source": [
        "# загрузим датасет на русском языке\n",
        "full_train = pyconll.load_from_file('/content/drive/MyDrive/Colab Notebooks/Учеба/GeekBrains/Введение в обработку естественного языка/Less 5/ru_syntagrus-ud-dev.conllu')\n",
        "full_test = pyconll.load_from_file('/content/drive/MyDrive/Colab Notebooks/Учеба/GeekBrains/Введение в обработку естественного языка/Less 5/ru_syntagrus-ud-test.conllu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdata_train = []\n",
        "for sent in full_train[:]:\n",
        "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
        "    \n",
        "fdata_test = []\n",
        "for sent in full_test[:]:\n",
        "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
        "    \n",
        "fdata_sent_test = []\n",
        "for sent in full_test[:]:\n",
        "    fdata_sent_test.append([token.form for token in sent])"
      ],
      "metadata": {
        "id": "exXFEF9m9Kzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пункт № 1:** проверить UnigramTagger, BigramTagger, TrigramTagger и их комбмнации\n",
        " "
      ],
      "metadata": {
        "id": "n9U4fvrgCE2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_tagger = UnigramTagger(fdata_train)\n",
        "display(unigram_tagger.tag(fdata_sent_test[100]), unigram_tagger.accuracy(fdata_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDPM0-kj_jRE",
        "outputId": "4a24640a-9588-40b1-8045-b06e99325655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('Вместе', 'ADV'),\n",
              " ('с', 'ADP'),\n",
              " ('тем', 'PRON'),\n",
              " (',', 'PUNCT'),\n",
              " ('доступ', 'NOUN'),\n",
              " ('в', 'ADP'),\n",
              " ('интернет', 'NOUN'),\n",
              " ('в', 'ADP'),\n",
              " ('РА', None),\n",
              " ('нельзя', 'ADV'),\n",
              " ('назвать', 'VERB'),\n",
              " ('дешевым', 'ADJ'),\n",
              " ('и', 'CCONJ'),\n",
              " ('общедоступным', None),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.7736867756615967"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_tagger = BigramTagger(fdata_train, backoff=unigram_tagger)\n",
        "display(bigram_tagger.tag(fdata_sent_test[100]), bigram_tagger.accuracy(fdata_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6WomN9S9m8u",
        "outputId": "a1ce7e02-0402-4f94-a5f3-ddc04e3cfc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('Вместе', 'ADV'),\n",
              " ('с', 'ADP'),\n",
              " ('тем', 'PRON'),\n",
              " (',', 'PUNCT'),\n",
              " ('доступ', 'NOUN'),\n",
              " ('в', 'ADP'),\n",
              " ('интернет', 'NOUN'),\n",
              " ('в', 'ADP'),\n",
              " ('РА', None),\n",
              " ('нельзя', 'ADV'),\n",
              " ('назвать', 'VERB'),\n",
              " ('дешевым', 'ADJ'),\n",
              " ('и', 'CCONJ'),\n",
              " ('общедоступным', None),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.7781807594199596"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_tagger = TrigramTagger(fdata_train, backoff=bigram_tagger)\n",
        "display(trigram_tagger.tag(fdata_sent_test[100]), trigram_tagger.accuracy(fdata_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kemAqE9CXo2",
        "outputId": "3330c29d-8284-41f6-bc38-b27401de9db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('Вместе', 'ADV'),\n",
              " ('с', 'ADP'),\n",
              " ('тем', 'PRON'),\n",
              " (',', 'PUNCT'),\n",
              " ('доступ', 'NOUN'),\n",
              " ('в', 'ADP'),\n",
              " ('интернет', 'NOUN'),\n",
              " ('в', 'ADP'),\n",
              " ('РА', None),\n",
              " ('нельзя', 'ADV'),\n",
              " ('назвать', 'VERB'),\n",
              " ('дешевым', 'ADJ'),\n",
              " ('и', 'CCONJ'),\n",
              " ('общедоступным', None),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.7776364177252847"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
        "    for cls in tagger_classes:\n",
        "        backoff = cls(train_sents, backoff=backoff)\n",
        "    return backoff\n",
        "\n",
        "\n",
        "backoff = DefaultTagger('NN') \n",
        "tag = backoff_tagger(fdata_train,  \n",
        "                     [UnigramTagger, BigramTagger, TrigramTagger],  \n",
        "                     backoff = backoff) \n",
        "  \n",
        "tag.accuracy(fdata_test) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBlFqDnrD5YL",
        "outputId": "da0e46ea-355e-4e09-b158-187b87c240ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7763135408161328"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пункт № 2:** написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов\n"
      ],
      "metadata": {
        "id": "dFToeuXsCmPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_tok = []\n",
        "train_label = []\n",
        "for sent in fdata_train[:]:\n",
        "    for tok in sent:\n",
        "        if tok[0] is not None:\n",
        "          train_tok.append(tok[0])\n",
        "          train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
        "        \n",
        "test_tok = []\n",
        "test_label = []\n",
        "for sent in fdata_test[:]:\n",
        "    for tok in sent:\n",
        "        if tok[0] is not None:\n",
        "          test_tok.append(tok[0])\n",
        "          test_label.append('NO_TAG' if tok[1] is None else tok[1])"
      ],
      "metadata": {
        "id": "pISUqBe-Co_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "train_enc_labels = le.fit_transform(train_label)\n",
        "test_enc_labels = le.transform(test_label)"
      ],
      "metadata": {
        "id": "Osbu5dzoKVAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hvectorizer = HashingVectorizer(ngram_range=(1, 3), analyzer='char', n_features=50)\n",
        "\n",
        "X_train = hvectorizer.fit_transform(train_tok)\n",
        "X_test = hvectorizer.transform(test_tok)"
      ],
      "metadata": {
        "id": "jEKQmJDaKqhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(random_state=12, max_iter=40)\n",
        "lr.fit(X_train, train_enc_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6NevV9rKw2o",
        "outputId": "e0d7f262-32d0-4e37-fb7b-32c12215fff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=40, random_state=12)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_pred = lr.predict(X_test)\n",
        "print(classification_report(test_enc_labels, lr_pred, target_names=le.classes_, output_dict=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH_zREbtKyfc",
        "outputId": "4f1fd706-7225-44e1-d5fb-020786a7789e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.48      0.32      0.38     14471\n",
            "         ADP       0.72      0.88      0.79     15062\n",
            "         ADV       0.33      0.11      0.17      8085\n",
            "         AUX       0.86      0.91      0.88      1518\n",
            "       CCONJ       0.78      0.97      0.87      5736\n",
            "         DET       0.47      0.36      0.41      4094\n",
            "        INTJ       0.00      0.00      0.00        23\n",
            "        NOUN       0.47      0.68      0.56     36568\n",
            "      NO_TAG       0.99      1.00      0.99       194\n",
            "         NUM       0.47      0.23      0.31      2528\n",
            "        PART       0.59      0.57      0.58      4921\n",
            "        PRON       0.46      0.46      0.46      8015\n",
            "       PROPN       0.20      0.02      0.03      5883\n",
            "       PUNCT       0.98      1.00      0.99     29463\n",
            "       SCONJ       0.72      0.82      0.77      2992\n",
            "         SYM       0.00      0.00      0.00       165\n",
            "        VERB       0.55      0.46      0.50     18146\n",
            "           X       0.00      0.00      0.00        48\n",
            "\n",
            "    accuracy                           0.63    157912\n",
            "   macro avg       0.50      0.49      0.48    157912\n",
            "weighted avg       0.61      0.63      0.60    157912\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xg_reg = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 7, alpha = 10, n_estimators = 50)\n",
        "xg_reg.fit(X_train, train_enc_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFOobuT_Oxuu",
        "outputId": "6cd6c1dd-8ac7-4abb-aa07-8c4e53c0c856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(alpha=10, max_depth=7, n_estimators=50,\n",
              "              objective='multi:softprob')"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = xg_reg.predict(X_test)\n",
        "print(classification_report(test_enc_labels, pred, target_names=le.classes_, output_dict=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYPosRL5PAv7",
        "outputId": "cb50310e-eff7-4d0d-a0aa-35c7d3f33ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.82      0.79      0.80     14471\n",
            "         ADP       0.99      0.99      0.99     15062\n",
            "         ADV       0.92      0.78      0.84      8085\n",
            "         AUX       0.86      0.97      0.91      1518\n",
            "       CCONJ       0.88      1.00      0.93      5736\n",
            "         DET       0.84      0.73      0.78      4094\n",
            "        INTJ       0.67      0.17      0.28        23\n",
            "        NOUN       0.77      0.93      0.85     36568\n",
            "      NO_TAG       1.00      1.00      1.00       194\n",
            "         NUM       0.88      0.71      0.79      2528\n",
            "        PART       0.98      0.73      0.84      4921\n",
            "        PRON       0.83      0.89      0.86      8015\n",
            "       PROPN       0.82      0.23      0.36      5883\n",
            "       PUNCT       0.99      1.00      1.00     29463\n",
            "       SCONJ       0.80      0.91      0.85      2992\n",
            "         SYM       1.00      0.74      0.85       165\n",
            "        VERB       0.87      0.80      0.84     18146\n",
            "           X       0.23      0.12      0.16        48\n",
            "\n",
            "    accuracy                           0.87    157912\n",
            "   macro avg       0.84      0.75      0.77    157912\n",
            "weighted avg       0.88      0.87      0.87    157912\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пункт №3:** сравнить все реализованные методы сделать выводы"
      ],
      "metadata": {
        "id": "zzJBKAa62eV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Написанная модель с помощью xgboost получила самые высокие результат accuracy, если рассмотреть подобрнее classification_report то видно что модель в целом обучилась очень хорошо, исключения составляет только совсем редкие экземпляры классов"
      ],
      "metadata": {
        "id": "DUuMBQL92lTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание №2:** Проверить насколько хорошо работает NER"
      ],
      "metadata": {
        "id": "yHm5ScDW3asB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пункт №1:** проверить NER из nltk/spacy/deeppavlov"
      ],
      "metadata": {
        "id": "kHMfUG923v6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на работу NLTK"
      ],
      "metadata": {
        "id": "ESnX6Mu8_ZxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.labinform.ru/pub/named_entities/collection5.zip\n",
        "!unzip collection5.zip"
      ],
      "metadata": {
        "id": "kky-linP3zAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = './Collection5/'"
      ],
      "metadata": {
        "id": "tAUZYGqQ_JXH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "for rec in load_ne5(dir):\n",
        "    words = []\n",
        "    labels = []\n",
        "    idx_ent = -1\n",
        "    len_ents = len(rec.spans)\n",
        "    rec_entities = sorted(rec.spans, key=lambda v: v.start)\n",
        "    ent = None\n",
        "    is_start = None\n",
        "    for token in tokenize(rec.text):\n",
        "        type_ent = 'OUT'\n",
        "        if len_ents == 0:\n",
        "            words.append(token.text)\n",
        "            labels.append(type_ent)\n",
        "            continue\n",
        "\n",
        "        if (idx_ent == -1) or (idx_ent + 1 < len_ents and token.start > ent.stop):\n",
        "            idx_ent += 1\n",
        "            ent = rec_entities[idx_ent]\n",
        "            is_start = True\n",
        "\n",
        "        if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
        "                type_ent = ent.type\n",
        "                is_start = False\n",
        "        words.append(token.text)\n",
        "        labels.append(type_ent)\n",
        "    \n",
        "    docs.append([words, labels])"
      ],
      "metadata": {
        "id": "SDGkpkrRe4uE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[1][0])\n",
        "print(docs[1][1])\n",
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMuAH9j8hDYV",
        "outputId": "0f3b768c-1bbc-4736-b721-e59ada8835ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Слащева', 'на', 'посту', 'главы', '\"', 'СТС', 'Медиа', '\"', 'займется', 'стратегией', 'и', 'продажами', 'С', '1', 'августа', 'гендиректором', '\"', 'СТС', 'Медиа', '\"', 'станет', 'президент', 'PR-агентства', '\"', 'Михайлов', 'и', 'партнеры', '\"', 'Юлиана', 'Слащева', '.', 'Президент', 'PR-агентства', '\"', 'Михайлов', 'и', 'партнеры', '\"', 'Юлиана', 'Слащева', ',', 'которая', ',', 'как', 'ожидается', ',', 'с', '1', 'августа', 'станет', 'гендиректором', '\"', 'СТС', 'Медиа', '\"', ',', 'в', 'новой', 'должности', 'займется', 'разработкой', 'стратегии', 'холдинга', ',', 'привлечением', 'творческих', 'сил', 'в', 'компанию', ',', 'а', 'также', 'усилением', 'активных', 'продаж', ',', 'сообщил', 'РИА', 'Новости', 'источник', ',', 'знакомый', 'с', 'ситуацией', '.', 'Газета', '\"', 'Ведомости', '\"', 'в', 'понедельник', 'со', 'ссылкой', 'на', 'источник', ',', 'близкий', 'к', 'акционерам', 'компании', ',', 'сообщила', 'о', 'возможной', 'отставке', 'гендиректора', '\"', 'СТС', 'Медиа', '\"', 'Бориса', 'Подольского', '.', 'Его', 'место', ',', 'по', 'данным', 'издания', ',', 'может', 'занять', 'Слащева', '.', 'Источник', 'подтвердил', 'РИА', 'Новости', ',', 'что', 'Слащева', 'будет', 'утверждена', 'в', 'качестве', 'генерального', 'директора', 'компании', 'на', 'ближайшем', 'совете', 'директоров', ',', 'который', 'пройдет', 'в', 'первых', 'числах', 'августа', '.', '\"', 'Компанией', 'очень', 'долгое', 'время', 'руководили', 'финансисты', '.', 'А', 'это', 'все-таки', 'компания', ',', 'требующая', 'стратегического', 'подхода', 'и', 'умения', 'управлять', ',', 'собирать', 'творческие', 'команды', '.', 'Потому', 'что', 'телевидение', '—', 'это', 'в', 'первую', 'очередь', 'креативные', 'люди', '.', 'А', 'обычно', 'финансисты', 'креативных', 'людей', 'не', 'очень', 'ценят', '\"', ',', '—', 'отметил', 'один', 'из', 'специалистов', 'медийного', 'рынка', '.', 'По', 'его', 'сведениям', ',', 'за', 'последние', 'пять', 'лет', 'многие', 'творческие', 'сотрудники', 'покинули', 'компанию', '.', 'Поэтому', 'перед', 'Слащевой', 'поставили', 'задачу', 'удержать', 'существующий', 'штат', ',', 'а', 'также', 'привлечь', 'новых', 'творческих', 'людей', ',', 'которые', 'умеют', 'делать', 'телевизионный', 'продукт', '.', '\"', 'СТС', 'Медиа', '\"', 'сейчас', 'необходима', 'стратегия', ',', 'потому', 'что', ',', 'действительно', ',', 'у', 'компании', 'нет', 'долгосрочной', 'стратегии', '.', 'И', 'это', ',', 'правда', ',', 'была', 'главная', 'претензия', ',', 'может', 'быть', ',', 'единственная', ',', 'у', 'акционеров', 'к', 'Подольскому', '.', 'Наверное', ',', 'была', 'еще', 'одна', ',', 'вытекающая', 'отсюда', '—', 'что', 'у', 'каналов', ',', 'вообще', 'у', 'компании', ',', 'было', 'недостаточно', 'маркетинга', 'и', 'активных', 'продаж', '\"', ',', '—', 'отметил', 'собеседник', 'агентства', '.', 'РИА', 'Новости', 'пока', 'не', 'удалось', 'получить', 'комментарий', 'Слащевой', 'по', 'этому', 'поводу', '.', 'В', 'холдинге', '\"', 'СТС', 'Медиа', '\"', 'отказались', 'комментировать', 'ситуацию', '.', '\"', 'Не', 'комментируем', ',', 'к', 'сожалению', '\"', ',', '—', 'заявили', 'в', 'компании', '.']\n",
            "['PER', 'OUT', 'OUT', 'OUT', 'MEDIA', 'MEDIA', 'MEDIA', 'MEDIA', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'MEDIA', 'MEDIA', 'MEDIA', 'OUT', 'OUT', 'OUT', 'ORG', 'ORG', 'ORG', 'ORG', 'ORG', 'ORG', 'PER', 'PER', 'OUT', 'OUT', 'ORG', 'ORG', 'ORG', 'ORG', 'ORG', 'ORG', 'PER', 'PER', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'MEDIA', 'MEDIA', 'MEDIA', 'MEDIA', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'MEDIA', 'MEDIA', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'MEDIA', 'MEDIA', 'MEDIA', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'MEDIA', 'MEDIA', 'MEDIA', 'MEDIA', 'PER', 'PER', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'PER', 'OUT', 'OUT', 'OUT', 'MEDIA', 'MEDIA', 'OUT', 'OUT', 'PER', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'PER', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'MEDIA', 'MEDIA', 'MEDIA', 'MEDIA', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'LOC', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'MEDIA', 'MEDIA', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'PER', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'MEDIA', 'MEDIA', 'MEDIA', 'MEDIA', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in nltk.ne_chunk(nltk.pos_tag(docs[1][0])):\n",
        "      if hasattr(chunk, 'label'):\n",
        "         print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5wsqh5diFWJ",
        "outputId": "185427d5-a1df-41e6-ce03-f9f37e808d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(PERSON Слащева/JJ)\n",
            "(PERSON Михайлов/NNP)\n",
            "(PERSON Юлиана/NNP Слащева/NNP)\n",
            "(PERSON Михайлов/NNP)\n",
            "(PERSON Юлиана/NNP Слащева/NNP)\n",
            "(PERSON Новости/NNP)\n",
            "(PERSON Бориса/NNP Подольского/NNP)\n",
            "(ORGANIZATION РИА/NNP Новости/NNP)\n",
            "(PERSON Слащева/NNP)\n",
            "(PERSON Компанией/JJ)\n",
            "(ORGANIZATION Слащевой/NNP)\n",
            "(ORGANIZATION СТС/JJ)\n",
            "(PERSON Наверное/NN)\n",
            "(PERSON Новости/JJ)\n",
            "(PERSON Не/JJ)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NTLK отработал средне, СТС помечена как организация, что очень хорошо, а вот наверное, новости и не, как персоны, что очень плохо"
      ],
      "metadata": {
        "id": "rp5k0g6a9Pdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на работу spacy"
      ],
      "metadata": {
        "id": "dHCQ1b4r_fHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "id": "E-Bj4eLwBz4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBYtY5uV_R_l",
        "outputId": "346e5a4b-d13a-479d-95f3-0be411fada84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ru-core-news-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.3.0/ru_core_news_sm-3.3.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 13.7 MB/s \n",
            "\u001b[?25hCollecting pymorphy2>=0.9\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-sm==3.3.0) (3.3.1)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.3.0) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (0.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (0.7.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.0.1)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2, ru-core-news-sm\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 ru-core-news-sm-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = []\n",
        "for doc in load_ne5(dir):\n",
        "  text.append(doc.text)"
      ],
      "metadata": {
        "id": "BBWhbAs8EhdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.ru.examples import sentences \n",
        "\n",
        "nlp = spacy.load(\"ru_core_news_sm\")"
      ],
      "metadata": {
        "id": "DRYvTQ7Q9Eih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in nlp(text[1]).ents:\n",
        "  print(ent.text.strip(), ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNe54rIfBMIr",
        "outputId": "2f55ea73-cac8-4222-cca6-181942ec30dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слащева PER\n",
            "СТС Медиа ORG\n",
            "СТС Медиа ORG\n",
            "PR-агентства ORG\n",
            "Михайлов и партнеры ORG\n",
            "Юлиана Слащева PER\n",
            "PR-агентства ORG\n",
            "Михайлов и партнеры ORG\n",
            "Юлиана Слащева PER\n",
            "СТС Медиа ORG\n",
            "РИА Новости ORG\n",
            "Ведомости ORG\n",
            "СТС Медиа ORG\n",
            "Бориса Подольского PER\n",
            "Слащева PER\n",
            "РИА Новости ORG\n",
            "Слащева PER\n",
            "Слащевой PER\n",
            "СТС Медиа ORG\n",
            "Подольскому PER\n",
            "РИА Новости ORG\n",
            "Слащевой PER\n",
            "СТС Медиа ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spacy отработал идеально"
      ],
      "metadata": {
        "id": "Wg_1K9IgG08F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем модель deeppavlov\n",
        "UPD: Нормально установить deeppavlov не получилось "
      ],
      "metadata": {
        "id": "ZCrjlyoTHAb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пункт №2:** написать свой нер попробовать разные подходы"
      ],
      "metadata": {
        "id": "8mdTgQZ1Hogb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Распарсим данные на x и y:\n",
        "words = []\n",
        "labels = []\n",
        "sentence = []\n",
        "\n",
        "sen_count = 1 # Маркеровка предложений\n",
        "for rec in load_ne5(dir):\n",
        "    idx_ent = -1\n",
        "    len_ents = len(rec.spans)\n",
        "    rec_entities = sorted(rec.spans, key=lambda v: v.start)\n",
        "    ent = None\n",
        "    is_start = None\n",
        "    for token in tokenize(rec.text):\n",
        "        type_ent = 'OUT'\n",
        "        if len_ents == 0:\n",
        "            words.append(token.text)\n",
        "            labels.append(type_ent)\n",
        "            continue\n",
        "\n",
        "        if (idx_ent == -1) or (idx_ent + 1 < len_ents and token.start > ent.stop):\n",
        "            idx_ent += 1\n",
        "            ent = rec_entities[idx_ent]\n",
        "            is_start = True\n",
        "\n",
        "        if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
        "                type_ent = ent.type\n",
        "                is_start = False\n",
        "        words.append(token.text)\n",
        "        labels.append(type_ent)\n",
        "        sentence.append(sen_count)\n",
        "        if token.text == \".\": # Т.к. у нас текст новости идет набором предложений, то разделем предложение по точкам\n",
        "          sen_count += 1"
      ],
      "metadata": {
        "id": "rrNxALMRR1ag"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'Sentence': sentence,'Word': words, 'Span': labels})\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zJuAm8xpHiRT",
        "outputId": "1c26ff38-7ea0-4b64-aa73-9a6b022cfccf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Sentence          Word      Span\n",
              "0              1         Новый       OUT\n",
              "1              1   командующий       OUT\n",
              "2              1     коалицией       OUT\n",
              "3              1             в       OUT\n",
              "4              1   Афганистане  GEOPOLIT\n",
              "...          ...           ...       ...\n",
              "265466     15091     курировал       OUT\n",
              "265467     15091         сферу       OUT\n",
              "265468     15091  межбюджетных       OUT\n",
              "265469     15091     отношений       OUT\n",
              "265470     15091             .       OUT\n",
              "\n",
              "[265471 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9edec066-6e47-416b-a87d-9bb678276b0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Новый</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>командующий</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>коалицией</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>в</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Афганистане</td>\n",
              "      <td>GEOPOLIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265466</th>\n",
              "      <td>15091</td>\n",
              "      <td>курировал</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265467</th>\n",
              "      <td>15091</td>\n",
              "      <td>сферу</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265468</th>\n",
              "      <td>15091</td>\n",
              "      <td>межбюджетных</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265469</th>\n",
              "      <td>15091</td>\n",
              "      <td>отношений</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265470</th>\n",
              "      <td>15091</td>\n",
              "      <td>.</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>265471 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9edec066-6e47-416b-a87d-9bb678276b0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9edec066-6e47-416b-a87d-9bb678276b0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9edec066-6e47-416b-a87d-9bb678276b0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Посмотрим на разброс таргета\n",
        "df['Span'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27gBxdccSS8T",
        "outputId": "5b9a0b77-95ba-4067-92ce-4328b5c5d3de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OUT         0.825755\n",
              "PER         0.079858\n",
              "ORG         0.051422\n",
              "LOC         0.017207\n",
              "GEOPOLIT    0.016409\n",
              "MEDIA       0.009349\n",
              "Name: Span, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dict_map(data, token_or_tag):\n",
        "    tok2idx = {}\n",
        "    idx2tok = {}\n",
        "    \n",
        "    if token_or_tag == 'token':\n",
        "        vocab = list(set(data['Word'].to_list()))\n",
        "    else:\n",
        "        vocab = list(set(data['Span'].to_list()))\n",
        "    \n",
        "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
        "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
        "    return tok2idx, idx2tok\n",
        "\n",
        "\n",
        "token2idx, idx2token = get_dict_map(df, 'token')\n",
        "tag2idx, idx2tag = get_dict_map(df, 'tag')"
      ],
      "metadata": {
        "id": "gmLA0eBFTbjS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx2tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyLQ02NOj7BG",
        "outputId": "f0eae380-844c-4d38-ce10-e8fd9ed3e77f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'LOC', 1: 'OUT', 2: 'PER', 3: 'ORG', 4: 'GEOPOLIT', 5: 'MEDIA'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Word_idx'] = df['Word'].map(token2idx)\n",
        "df['Span_idx'] = df['Span'].map(tag2idx)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mlGWSikzUpYf",
        "outputId": "a6c1e018-18d6-44fa-e9a6-cc7dd6a094ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sentence         Word      Span  Word_idx  Span_idx\n",
              "0         1        Новый       OUT     28589         1\n",
              "1         1  командующий       OUT      9246         1\n",
              "2         1    коалицией       OUT     12427         1\n",
              "3         1            в       OUT     32100         1\n",
              "4         1  Афганистане  GEOPOLIT     21793         4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-423bfa60-b28a-407a-92d2-f09e65f80485\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Span</th>\n",
              "      <th>Word_idx</th>\n",
              "      <th>Span_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Новый</td>\n",
              "      <td>OUT</td>\n",
              "      <td>28589</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>командующий</td>\n",
              "      <td>OUT</td>\n",
              "      <td>9246</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>коалицией</td>\n",
              "      <td>OUT</td>\n",
              "      <td>12427</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>в</td>\n",
              "      <td>OUT</td>\n",
              "      <td>32100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Афганистане</td>\n",
              "      <td>GEOPOLIT</td>\n",
              "      <td>21793</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-423bfa60-b28a-407a-92d2-f09e65f80485')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-423bfa60-b28a-407a-92d2-f09e65f80485 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-423bfa60-b28a-407a-92d2-f09e65f80485');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Группируем\n",
        "data_group = df.groupby(\n",
        "['Sentence'],as_index=False\n",
        ")['Word', 'Span', 'Word_idx', 'Span_idx'].agg(lambda x: list(x))\n",
        "# Смотрим\n",
        "data_group"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "TxLh2w-EUxFV",
        "outputId": "e920791c-c123-4afb-8e59-503cefdeea0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Sentence                                               Word  \\\n",
              "0             1  [Новый, командующий, коалицией, в, Афганистане...   \n",
              "1             2  [Официальная, церемония, вступления, генерала,...   \n",
              "2             3  [Маккристал, ,, ранее, командовавший, в, Ираке...   \n",
              "3             4  [\", Мерой, эффективности, будет, служить, не, ...   \n",
              "4             5  [Гибель, мирных, жителей, в, ходе, операций, ,...   \n",
              "...         ...                                                ...   \n",
              "15086     15087  [Заместителем, министра, финансов, РФ, в, перв...   \n",
              "15087     15088                              [В, 2004-2005, гг, .]   \n",
              "15088     15089  [он, был, директором, департамента, межбюджетн...   \n",
              "15089     15090                             [С, конца, 2005, г, .]   \n",
              "15090     15091  [работал, в, должности, заместителя, министра,...   \n",
              "\n",
              "                                                    Span  \\\n",
              "0      [OUT, OUT, OUT, OUT, GEOPOLIT, OUT, OUT, OUT, ...   \n",
              "1      [OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, ...   \n",
              "2      [PER, OUT, OUT, OUT, OUT, GEOPOLIT, OUT, GEOPO...   \n",
              "3      [OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, ...   \n",
              "4      [OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, ...   \n",
              "...                                                  ...   \n",
              "15086  [OUT, OUT, OUT, GEOPOLIT, OUT, OUT, OUT, OUT, ...   \n",
              "15087                               [OUT, OUT, OUT, OUT]   \n",
              "15088           [OUT, OUT, OUT, OUT, OUT, OUT, ORG, OUT]   \n",
              "15089                          [OUT, OUT, OUT, OUT, OUT]   \n",
              "15090  [OUT, OUT, OUT, OUT, OUT, OUT, GEOPOLIT, OUT, ...   \n",
              "\n",
              "                                                Word_idx  \\\n",
              "0      [28589, 9246, 12427, 32100, 21793, 20939, 1179...   \n",
              "1      [21983, 28167, 20870, 19313, 32100, 11727, 344...   \n",
              "2      [27330, 2556, 21124, 18695, 32100, 2645, 13740...   \n",
              "3      [16507, 243, 9381, 24909, 15723, 31513, 9292, ...   \n",
              "4      [21344, 1189, 30596, 32100, 9265, 12372, 2556,...   \n",
              "...                                                  ...   \n",
              "15086  [23045, 21336, 20775, 20231, 32100, 21848, 830...   \n",
              "15087                       [23652, 20032, 19792, 32167]   \n",
              "15088  [32381, 32213, 27062, 19103, 25809, 12776, 110...   \n",
              "15089                  [19915, 20698, 3495, 2730, 32167]   \n",
              "15090  [16352, 32100, 20639, 1851, 21336, 20775, 2023...   \n",
              "\n",
              "                                                Span_idx  \n",
              "0      [1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, ...  \n",
              "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "2      [2, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, ...  \n",
              "...                                                  ...  \n",
              "15086         [1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "15087                                       [1, 1, 1, 1]  \n",
              "15088                           [1, 1, 1, 1, 1, 1, 3, 1]  \n",
              "15089                                    [1, 1, 1, 1, 1]  \n",
              "15090            [1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1]  \n",
              "\n",
              "[15091 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb14d898-68e6-4e4f-8cc8-86c2874cd10f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Span</th>\n",
              "      <th>Word_idx</th>\n",
              "      <th>Span_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[Новый, командующий, коалицией, в, Афганистане...</td>\n",
              "      <td>[OUT, OUT, OUT, OUT, GEOPOLIT, OUT, OUT, OUT, ...</td>\n",
              "      <td>[28589, 9246, 12427, 32100, 21793, 20939, 1179...</td>\n",
              "      <td>[1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[Официальная, церемония, вступления, генерала,...</td>\n",
              "      <td>[OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, ...</td>\n",
              "      <td>[21983, 28167, 20870, 19313, 32100, 11727, 344...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[Маккристал, ,, ранее, командовавший, в, Ираке...</td>\n",
              "      <td>[PER, OUT, OUT, OUT, OUT, GEOPOLIT, OUT, GEOPO...</td>\n",
              "      <td>[27330, 2556, 21124, 18695, 32100, 2645, 13740...</td>\n",
              "      <td>[2, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[\", Мерой, эффективности, будет, служить, не, ...</td>\n",
              "      <td>[OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, ...</td>\n",
              "      <td>[16507, 243, 9381, 24909, 15723, 31513, 9292, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[Гибель, мирных, жителей, в, ходе, операций, ,...</td>\n",
              "      <td>[OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, OUT, ...</td>\n",
              "      <td>[21344, 1189, 30596, 32100, 9265, 12372, 2556,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15086</th>\n",
              "      <td>15087</td>\n",
              "      <td>[Заместителем, министра, финансов, РФ, в, перв...</td>\n",
              "      <td>[OUT, OUT, OUT, GEOPOLIT, OUT, OUT, OUT, OUT, ...</td>\n",
              "      <td>[23045, 21336, 20775, 20231, 32100, 21848, 830...</td>\n",
              "      <td>[1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15087</th>\n",
              "      <td>15088</td>\n",
              "      <td>[В, 2004-2005, гг, .]</td>\n",
              "      <td>[OUT, OUT, OUT, OUT]</td>\n",
              "      <td>[23652, 20032, 19792, 32167]</td>\n",
              "      <td>[1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15088</th>\n",
              "      <td>15089</td>\n",
              "      <td>[он, был, директором, департамента, межбюджетн...</td>\n",
              "      <td>[OUT, OUT, OUT, OUT, OUT, OUT, ORG, OUT]</td>\n",
              "      <td>[32381, 32213, 27062, 19103, 25809, 12776, 110...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 3, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15089</th>\n",
              "      <td>15090</td>\n",
              "      <td>[С, конца, 2005, г, .]</td>\n",
              "      <td>[OUT, OUT, OUT, OUT, OUT]</td>\n",
              "      <td>[19915, 20698, 3495, 2730, 32167]</td>\n",
              "      <td>[1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15090</th>\n",
              "      <td>15091</td>\n",
              "      <td>[работал, в, должности, заместителя, министра,...</td>\n",
              "      <td>[OUT, OUT, OUT, OUT, OUT, OUT, GEOPOLIT, OUT, ...</td>\n",
              "      <td>[16352, 32100, 20639, 1851, 21336, 20775, 2023...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15091 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb14d898-68e6-4e4f-8cc8-86c2874cd10f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb14d898-68e6-4e4f-8cc8-86c2874cd10f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb14d898-68e6-4e4f-8cc8-86c2874cd10f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pad_train_test_val(data_group, data):\n",
        "\n",
        "    #get max token and tag length\n",
        "    n_token = len(list(set(data['Word'].to_list())))\n",
        "    n_tag = len(list(set(data['Span'].to_list())))\n",
        "\n",
        "    #Pad tokens (X var)    \n",
        "    tokens = data_group['Word_idx'].tolist()\n",
        "    maxlen = max([len(s) for s in tokens])\n",
        "    print('maxlen = {}'.format(maxlen))\n",
        "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
        "\n",
        "    #Pad Tags (y var) and convert it into one hot encoding\n",
        "    tags = data_group['Span_idx'].tolist()\n",
        "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"OUT\"])\n",
        "    n_tags = len(tag2idx)\n",
        "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
        "    \n",
        "    #Split train, test and validation set\n",
        "    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
        "    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_,tags_,test_size = 0.25,train_size =0.75, random_state=2020)\n",
        "\n",
        "    print(\n",
        "        'train_tokens length:', len(train_tokens),\n",
        "        '\\ntrain_spans length:', len(train_tags),\n",
        "        '\\ntest_tokens length:', len(test_tokens),\n",
        "        '\\ntest_spans:', len(test_tags),\n",
        "        '\\nval_tokens:', len(val_tokens),\n",
        "        '\\nval_spans:', len(val_tags),\n",
        "    )\n",
        "    \n",
        "    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags\n",
        "\n",
        "train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(data_group, df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "097VqL5efEAF",
        "outputId": "8518ef1a-6953-4359-de33-a71aac930a42"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxlen = 222\n",
            "train_tokens length: 10185 \n",
            "train_spans length: 10185 \n",
            "test_tokens length: 1510 \n",
            "test_spans: 1510 \n",
            "val_tokens: 3396 \n",
            "val_spans: 3396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(list(set(df['Word'].to_list()))) + 1\n",
        "output_dim = 64\n",
        "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
        "n_tags = len(tag2idx)\n",
        "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRu-XMyRgrLb",
        "outputId": "3e97b6c2-151a-47db-f0b8-6346e8264564"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_dim:  34940 \n",
            "output_dim:  64 \n",
            "input_length:  222 \n",
            "n_tags:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bilstm_lstm_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Слой Embedding\n",
        "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "\n",
        "    # Слой bidirectional LSTM\n",
        "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
        "\n",
        "    # Слой LSTM\n",
        "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
        "\n",
        "    # Слой timeDistributed Layer (обеспечивает выход формата many-to-many)\n",
        "    model.add(TimeDistributed(Dense(n_tags, activation=\"LeakyReLU\")))\n",
        "\n",
        "    #Optimiser \n",
        "    # adam =  tensorflow.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "DnKRSIlpgnge"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bilstm_lstm = get_bilstm_lstm_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of3rm_18g5nL",
        "outputId": "0ca89a58-6dcf-49ff-bd02-c0fc0a3ec7a9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 222, 64)           2236160   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 222, 128)         66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 222, 64)           49408     \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 222, 6)           390       \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,352,006\n",
            "Trainable params: 2,352,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X, y, model):\n",
        "    loss = list()\n",
        "    for i in range(3):\n",
        "        # fit model for one epoch on this sequence\n",
        "        hist = model.fit(X, y, batch_size=128, verbose=1, epochs=1, validation_split=0.2)\n",
        "        loss.append(hist.history['loss'][0])\n",
        "    return loss"
      ],
      "metadata": {
        "id": "g7gvL7Dphm9v"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame()\n",
        "model_bilstm_lstm = get_bilstm_lstm_model()\n",
        "plot_model(model_bilstm_lstm)\n",
        "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06HMmGrIhrr2",
        "outputId": "e5e0979b-c587-489a-aa3c-61cee1d2d0a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 222, 64)           2236160   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 222, 128)         66048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 222, 64)           49408     \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 222, 6)           390       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,352,006\n",
            "Trainable params: 2,352,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "64/64 [==============================] - 140s 2s/step - loss: 0.4538 - accuracy: 0.9562 - val_loss: 0.1165 - val_accuracy: 0.9867\n",
            "64/64 [==============================] - 120s 2s/step - loss: 0.1239 - accuracy: 0.9849 - val_loss: 0.1135 - val_accuracy: 0.9846\n",
            "64/64 [==============================] - 119s 2s/step - loss: 0.2774 - accuracy: 0.9573 - val_loss: 0.1184 - val_accuracy: 0.9866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model_bilstm_lstm.predict(test_tokens)"
      ],
      "metadata": {
        "id": "Qxs7MUbexF4c"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = 105\n",
        "np.argmax(predict[num], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkssKB0s8fEd",
        "outputId": "1116c11e-8909-4c57-e44b-90570a128cf4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(test_tags[num], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PFPtJNF80JK",
        "outputId": "f3d5c542-8a33-48e9-8d28-5d78e16b79ff"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** Как видно модель обучилась выставлять 1 (OUT), связано с дисбалансом классов, можно решить если уменьшить 1 класс, нагенерировать исскуственные данные не 1 класса, или может быть сводить предложения к одному усредненому вектору, но дисбаланс слишком большой"
      ],
      "metadata": {
        "id": "6PUdVjE6yaDf"
      }
    }
  ]
}